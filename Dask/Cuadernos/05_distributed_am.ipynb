{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <span style=\"color:green\"><center>Diplomado en Big Data</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"><center> Dask Distributed: Ejecución distribuida<center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/dask_horizontal.svg\" align=\"right\" width=\"30%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Profesores</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Alvaro Mauricio Montenegro Díaz, ammontenegrod@unal.edu.co\n",
    "2. Daniel Mauricio Montenegro Reyes, dextronomo@gmail.com "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Asesora Medios y Marketing digital</span>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Maria del Pilar Montenegro, pmontenegro88@gmail.com "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Contenido</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* [Introducción](#Introducción)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Fuente</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta es una traducción libre del tutorial disponible en [dask-tutorial](https://github.com/dask/dask-tutorial)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Introducción</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hemos visto hasta ahora, Dask le permite simplemente construir grafos de tareas con dependencias, así como tener grafos creados automáticamente para usted usando sintaxis funcional con Numpy o Pandas en colecciones de datos. Nada de esto sería muy útil, si no hubiera también una forma de ejecutar estos grafos, de forma paralela y consciente de la memoria. Hasta ahora hemos estado llamando a `thing.compute()` o `dask.compute(thing)` sin preocuparnos de lo que esto implica. Ahora discutiremos las opciones disponibles para esa ejecución, y en particular, el programador distribuido (`distributed scheduler`), que viene con funcionalidad adicional.\n",
    "\n",
    "Dask viene con cuatro programadores disponibles:\n",
    "\n",
    "- \"threaded\" (aka \"threading\"): un programador respaldado por un grupo de subprocesos\n",
    "- \"processes\": un programador respaldado por un grupo de procesos\n",
    "- \"single-threaded\" (aka \"sync\"): Un planificador síncrono, bueno para la depuración\n",
    "- distributed: un programador distribuido para ejecutar grafos en varias máquinas, consulte abajo.\n",
    "\n",
    "Para seleccionar uno de estos para el cálculo, puede especificarlo en el momento de solicitar un resultado, p. Ej.,\n",
    "```python\n",
    "myvalue.compute(scheduler=\"single-threaded\")  # for debugging\n",
    "```\n",
    "\n",
    "También puede configurar un programador predeterminado ya sea temporalmente\n",
    "```python\n",
    "with dask.config.set(scheduler='processes'):\n",
    "    # set temporarily for this block only\n",
    "    # all compute calls within this block will use the specified scheduler\n",
    "    myvalue.compute()\n",
    "    anothervalue.compute()\n",
    "```\n",
    "\n",
    "O globalmente\n",
    "```python\n",
    "# set until further notice\n",
    "dask.config.set(scheduler='processes')\n",
    "```\n",
    "\n",
    "Probemos algunos programadores en el caso familiar de los datos de vuelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run prep.py -d flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dd.Scalar<series-..., dtype=float64>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import os\n",
    "df = dd.read_csv(os.path.join('../data/', 'nycflights', '*.csv'),\n",
    "                 parse_dates={'Date': [0, 1, 2]},\n",
    "                 dtype={'TailNum': object,\n",
    "                        'CRSElapsedTime': float,\n",
    "                        'Cancelled': bool})\n",
    "\n",
    "# Maximum average non-cancelled delay grouped by Airport\n",
    "largest_delay = df[~df.Cancelled].groupby('Origin').DepDelay.mean().max()\n",
    "largest_delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " threading, 9.5240 s; result, 10.35 hours\n",
      " processes, 19.3503 s; result, 10.35 hours\n",
      "      sync, 10.4881 s; result, 10.35 hours\n"
     ]
    }
   ],
   "source": [
    "# each of the following gives the same results (you can check!)\n",
    "# any surprises?\n",
    "import time\n",
    "for sch in ['threading', 'processes', 'sync']:\n",
    "    t0 = time.time()\n",
    "    r = largest_delay.compute(scheduler=sch)\n",
    "    t1 = time.time()\n",
    "    print(f\"{sch:>10}, {t1 - t0:0.4f} s; result, {r:0.2f} hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algunas preguntas a considerar:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cuánta aceleración es posible para esta tarea (pista, revise el grafo).\n",
    "- Teniendo en cuenta la cantidad de núcleos que hay en esta máquina, cuánto más rápidos podrían ser los programadores paralelos comparados con el programador de un solo subproceso.\n",
    "- ¿Cuánto más rápido fue usar hilos en un solo hilo? ¿Por qué esto difiere de la aceleración óptima?\n",
    "- ¿Por qué el planificador de multiprocesamiento es mucho más lento aquí?\n",
    "\n",
    "El programador `threaded` es una buena elección para trabajar con grandes conjuntos de datos fuera del núcleo en una sola máquina, siempre que las funciones que se utilizan liberen [GIL](https://blockgeni.com/tutorial-python-global-interpreter-lock/) la mayor parte del tiempo. NumPy y Pandas liberan el GIL en la mayoría de los lugares, por lo que el programador `threaded` es el predeterminado para `dask.array` y `dask.dataframe`. El planificador distribuido, tal vez con `process = False`, también funcionará bien para estas cargas de trabajo en una sola máquina.\n",
    "\n",
    "Para cargas de trabajo que contienen GIL, como es común con `dask.bag` y el código personalizado envuelto con `dask.delayed`, se recomienda usar el programador distribuido, incluso en una sola máquina. En términos generales, es más inteligente y proporciona mejores diagnósticos que el programador de \"procesos\".\n",
    "https://docs.dask.org/en/latest/scheduling.html proporciona algunos detalles adicionales sobre la elección de un planificador.\n",
    "\n",
    "Para escalar el trabajo en un clúster, se requiere el programador distribuido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construyendo un cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El sistema `dask.distributed` se compone de un único planificador centralizado y uno o más procesos de trabajo. [Implementar](https://docs.dask.org/en/latest/setup.html) un clúster Dask remoto implica un esfuerzo adicional. Pero hacer cosas localmente solo implica crear un objeto `Client`, que le permite interactuar con el\" clúster \"(subprocesos o procesos locales en su máquina). Para obtener más información, consulte [aquí](https://docs.dask.org/en/latest/setup/single-distributed.html).\n",
    "\n",
    "Tenga en cuenta que `Client()` toma muchos [argumentos](https://distributed.dask.org/en/latest/local-cluster.html#api)  opcionales , para configurar el número de procesos/subprocesos, límites de memoria y otros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "754b80cd28394de3b14907deb2617d79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>LocalCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n  <style scoped>\\n    …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "# Setup a local cluster.\n",
    "# By default this sets up 1 worker per core\n",
    "client = Client()\n",
    "client.cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si no está en jupyterlab y utiliza el `dask-labextension`, asegúrese de hacer clic en el enlace`Dashboard` para abrir el tablero de diagnóstico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecutando con el cliente distribuido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considere un cálculo trivial, como el que hemos usado antes, donde hemos agregado declaraciones de sueño para simular el trabajo real que se está realizando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import delayed\n",
    "import time\n",
    "\n",
    "def inc(x):\n",
    "    time.sleep(5)\n",
    "    return x + 1\n",
    "\n",
    "def dec(x):\n",
    "    time.sleep(3)\n",
    "    return x - 1\n",
    "\n",
    "def add(x, y):\n",
    "    time.sleep(7)\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De forma predeterminada, la creación de un `Cliente` lo convierte en el planificador predeterminado. Cualquier llamada a `.compute` usará el clúster al que está adjunto su `cliente`, a menos que especifique lo contrario, como se indicó anteriormente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = delayed(inc)(1)\n",
    "y = delayed(dec)(2)\n",
    "total = delayed(add)(x, y)\n",
    "total.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las tareas aparecerán en la interfaz de usuario web a medida que el clúster las procese y, finalmente, se imprimirá un resultado como salida de la celda anterior. Tenga en cuenta que el kernel está bloqueado mientras espera el resultado. El gráfico de bloques de tareas resultante podría tener un aspecto similar al siguiente. Al pasar el cursor sobre cada bloque, se indica con qué función se relaciona y cuánto tiempo tardó en ejecutarse. ![esto](../images/tasks.png)\n",
    "\n",
    "También puede ver una versión simplificada del gráfico que se está ejecutando en el panel Gráfico del tablero, siempre que el cálculo esté en curso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regresemos al cálculo de vuelos de antes y veamos qué sucede en el tablero (es posible que desee tener el portátil y el tablero uno al lado del otro). ¿Cómo funcionó esto en comparación con antes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.45 s, sys: 193 ms, total: 1.64 s\n",
      "Wall time: 8.41 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.351298909519874"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time largest_delay.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso particular, esto debería ser tan rápido o más rápido que en el mejor de los casos, `threaded` arriba. ¿Qué supones que es esto? Debe comenzar su lectura [aquí](https://distributed.dask.org/en/latest/index.html#architecture) y, en particular, tenga en cuenta que el programador distribuido fue una reescritura completa con más inteligencia sobre el intercambio de resultados intermedios y qué tareas se ejecutan en qué trabajador. Esto dará como resultado un mejor rendimiento en *algunos* casos, pero una latencia y una sobrecarga aún mayores en comparación con el programador de subprocesos, por lo que habrá casos raros en los que se desempeñe peor. Afortunadamente, el panel ahora nos brinda mucha más [información de diagnóstico](https://distributed.dask.org/en/latest/diagnosing-performance.html). Mire la página Perfil del tablero para averiguar qué es lo que toma la mayor fracción de tiempo de CPU para el cálculo que acabamos de realizar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si todo lo que quiere hacer es ejecutar cálculos creados usando retrasos, o ejecutar cálculos basados en las colecciones de datos de nivel superior, entonces eso es todo lo que necesita saber para escalar su trabajo a escala de clúster. Sin embargo, hay más detalles que conocer sobre el programador distribuido que ayudará con el uso eficiente. Consulte el capítulo Distribuido, Avanzado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecute los siguientes cálculos mientras mira la página de diagnóstico. En cada caso, ¿qué está tomando más tiempo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of flights\n",
    "_ = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of non-cancelled flights\n",
    "_ = len(df[~df.Cancelled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of non-cancelled flights per-airport\n",
    "_ = df[~df.Cancelled].groupby('Origin').Origin.count().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average departure delay from each airport?\n",
    "_ = df[~df.Cancelled].groupby('Origin').DepDelay.mean().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average departure delay per day-of-week\n",
    "_ = df.groupby(df.Date.dt.dayofweek).DepDelay.mean().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.client - ERROR - Failed to reconnect to scheduler after 10.00 seconds, closing client\n",
      "_GatheringFuture exception was never retrieved\n",
      "future: <_GatheringFuture finished exception=CancelledError()>\n",
      "asyncio.exceptions.CancelledError\n"
     ]
    }
   ],
   "source": [
    "client.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
