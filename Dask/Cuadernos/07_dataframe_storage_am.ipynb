{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <span style=\"color:green\"><center>Diplomado en Big Data</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"><center>Almacenamiento de dataframes<center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/dask_horizontal.svg\" align=\"right\" width=\"30%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Profesores</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Alvaro Mauricio Montenegro Díaz, ammontenegrod@unal.edu.co\n",
    "2. Daniel Mauricio Montenegro Reyes, dextronomo@gmail.com "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Asesora Medios y Marketing digital</span>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Maria del Pilar Montenegro, pmontenegro88@gmail.com "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Contenido</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* [Introducción](#Introducción)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Fuente</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta es una traducción libre del tutorial disponible en [dask-tutorial](https://github.com/dask/dask-tutorial)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Introducción</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/hdd.jpg\" width=\"20%\" align=\"right\">\n",
    "\n",
    "\n",
    "El almacenamiento eficiente puede mejorar drásticamente el rendimiento, especialmente cuando se opera repetidamente desde el disco.\n",
    "\n",
    "Descomprimir texto y analizar archivos CSV es caro. Una de las estrategias más efectivas  es utilizar un formato de almacenamiento binario como HDF5. A menudo, las ganancias de rendimiento al hacer esto son suficientes para que pueda volver a usar Pandas nuevamente en lugar de usar `dask.dataframe`.\n",
    "\n",
    "En esta sección, aprenderemos cómo organizar y almacenar de manera eficiente sus conjuntos de datos en formatos binarios en disco. Usaremos lo siguiente:\n",
    "\n",
    "\n",
    "1.  Formato [Pandas `HDFStore`](http://pandas.pydata.org/pandas-docs/stable/io.html#io-hdf5) sobre `HDF5`\n",
    "2.  `Categoricals` para almacenar datos de texto numéricamente\n",
    "\n",
    "**Principales conclusiones**\n",
    "\n",
    "1. Los formatos de almacenamiento afectan el rendimiento en un orden de magnitud\n",
    "2. Los datos de texto mantendrán lento incluso un formato rápido como HDF5\n",
    "3. Una combinación de formatos binarios, almacenamiento de columnas y datos particionados convierte tiempos de espera de un segundo en tiempos de espera de 80 ms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run prep.py -d accounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Lectura CSV</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero leemos nuestros datos *csv* como antes.\n",
    "\n",
    "CSV y otros formatos de archivo basados en texto son el almacenamiento más común para datos de muchas fuentes, ya que requieren un preprocesamiento mínimo, se pueden escribir línea por línea y son legibles por humanos. Dado que Pandas '`read_csv` está bien optimizado, los CSV son una entrada razonable, pero están lejos de estar optimizados, ya que la lectura requiere un análisis de texto extenso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/accounts.*.csv'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "filename = os.path.join('../data', 'accounts.*.csv')\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>names</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66</td>\n",
       "      <td>Ursula</td>\n",
       "      <td>-839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>272</td>\n",
       "      <td>Victor</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>275</td>\n",
       "      <td>Hannah</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>267</td>\n",
       "      <td>Victor</td>\n",
       "      <td>888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>318</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id   names  amount\n",
       "0   66  Ursula    -839\n",
       "1  272  Victor     422\n",
       "2  275  Hannah     406\n",
       "3  267  Victor     888\n",
       "4  318   Sarah     795"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "df_csv = dd.read_csv(filename)\n",
    "df_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escritura a  HDF5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HDF5 y netCDF son formatos de arreglos binarios muy utilizados en el ámbito científico.\n",
    "\n",
    "Pandas contiene un formato HDF5 especializado, `HDFStore`. El método `dd.DataFrame.to_hdf` funciona exactamente como el método `pd.DataFrame.to_hdf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/accounts.h5'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = os.path.join('../data', 'accounts.h5')\n",
    "target"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conda install -c anaconda pytables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.54 s, sys: 320 ms, total: 4.85 s\n",
      "Wall time: 4.89 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../data/accounts.h5', '../data/accounts.h5', '../data/accounts.h5']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to binary format, takes some time up-front\n",
    "%time df_csv.to_hdf(target, '../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>names</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66</td>\n",
       "      <td>Ursula</td>\n",
       "      <td>-839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>272</td>\n",
       "      <td>Victor</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>275</td>\n",
       "      <td>Hannah</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>267</td>\n",
       "      <td>Victor</td>\n",
       "      <td>888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>318</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id   names  amount\n",
       "0   66  Ursula    -839\n",
       "1  272  Victor     422\n",
       "2  275  Hannah     406\n",
       "3  267  Victor     888\n",
       "4  318   Sarah     795"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same data as before\n",
    "df_hdf = dd.read_hdf(target, '../data')\n",
    "df_hdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación de las velocidades CSV y HDF5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos un cálculo simple que requiere leer una columna de nuestro conjunto de datos y comparar el rendimiento entre los archivos CSV y nuestro archivo HDF5 recién creado. ¿Cuál esperas que sea más rápido?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 863 ms, sys: 102 ms, total: 964 ms\n",
      "Wall time: 423 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2661358724"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time df_csv.amount.sum().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.1 s, sys: 338 ms, total: 3.44 s\n",
      "Wall time: 3.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2661358724"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time df_hdf.amount.sum().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lamentablemente, son casi iguales, o quizás incluso más lentos.\n",
    "\n",
    "El culpable aquí es la columna `names`, que es de tipo`object` y, por lo tanto, es difícil de almacenar de manera eficiente. Hay dos problemas aquí:\n",
    "\n",
    "1. ¿Cómo almacenamos datos de texto como *nombres* de manera eficiente en el disco?\n",
    "2. ¿Por qué tuvimos que leer la columna *nombres* cuando todo lo que queríamos era *cantidad*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   Almacenamiento eficiente de carateres con categoricals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos usar categorías de Pandas para reemplazar nuestros tipos de objetos con una representación numérica. Esto lleva un poco más de tiempo desde el principio, pero da como resultado un mejor rendimiento.\n",
    "\n",
    "Más sobre categóricos en el [pandas docs](http://pandas.pydata.org/pandas-docs/stable/categorical.html) y en [este blogpost](http://matthewrocklin.com/blog/work/2015/06/18/Categoricals)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.54 s, sys: 791 ms, total: 10.3 s\n",
      "Wall time: 10.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../data/accounts.h5', '../data/accounts.h5', '../data/accounts.h5']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Categorize data, then store in HDFStore\n",
    "%time df_hdf.categorize(columns=['names']).to_hdf(target, '../data2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>names</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66</td>\n",
       "      <td>Ursula</td>\n",
       "      <td>-839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>272</td>\n",
       "      <td>Victor</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>275</td>\n",
       "      <td>Hannah</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>267</td>\n",
       "      <td>Victor</td>\n",
       "      <td>888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>318</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id   names  amount\n",
       "0   66  Ursula    -839\n",
       "1  272  Victor     422\n",
       "2  275  Hannah     406\n",
       "3  267  Victor     888\n",
       "4  318   Sarah     795"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It looks the same\n",
    "df_hdf = dd.read_hdf(target, '../data2')\n",
    "df_hdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 316 ms, sys: 94.6 ms, total: 410 ms\n",
      "Wall time: 410 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2661358724"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# But loads more quickly\n",
    "%time df_hdf.amount.sum().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto ahora es definitivamente más rápido que antes. Esto nos dice que no es solo el tipo de archivo que usamos, sino también cómo representamos nuestras variables lo que influye en el rendimiento del almacenamiento.\n",
    "\n",
    "¿Cómo depende el rendimiento de la lectura del programador que utilizamos? Puede probar esto con subprocesos, procesos y distribuidos.\n",
    "\n",
    "Sin embargo, esto aún puede ser mejor. Tuvimos que leer todas las columnas (`nombres` y `monto`) para calcular la suma de uno (`monto`). Mejoraremos aún más esto con `parquet`, un almacén de columnas en disco. Sin embargo, primero aprendemos cómo establecer un índice en un dask.dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fastparquet` es una librería para interactuar con archivos en formato parquet, que son un formato muy común en el ecosistema de Big Data, y utilizado por herramientas como Hadoop, Spark e Impala."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conda install -c conda-forge fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = os.path.join('../data', 'accounts.parquet')\n",
    "df_csv.categorize(columns=['names']).to_parquet(target, storage_options={\"has_nulls\": True}, engine=\"fastparquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigue la estructura de archivos en el nuevo directorio resultante: ¿para qué supone que son esos archivos?\n",
    "\n",
    "`to_parquet` viene con muchas opciones, como compresión, si escribir explícitamente información NULL (no es necesario en este caso) y cómo codificar cadenas. Puede experimentar con ellos para ver qué efecto tienen en el tamaño del archivo y los tiempos de procesamiento, a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 73268\n",
      "-rw-rw-r-- 1 alvaro alvaro      952 Jun 16 16:55 _common_metadata\n",
      "-rw-rw-r-- 1 alvaro alvaro     2227 Jun 16 16:55 _metadata\n",
      "-rw-rw-r-- 1 alvaro alvaro 25002096 Jun 16 16:55 part.0.parquet\n",
      "-rw-rw-r-- 1 alvaro alvaro 25002096 Jun 16 16:55 part.1.parquet\n",
      "-rw-rw-r-- 1 alvaro alvaro 25002096 Jun 16 16:55 part.2.parquet\n"
     ]
    }
   ],
   "source": [
    "ls -l data/accounts.parquet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           int64\n",
       "names     category\n",
       "amount       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p = dd.read_parquet(target)\n",
    "# note that column names shows the type of the values - we could\n",
    "# choose to load as a categorical column or not.\n",
    "df_p.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vuelva a ejecutar el cálculo de la suma anterior para esta versión de los datos y el tiempo que tarda. Es posible que desee probar esto más de una vez; es común que muchas bibliotecas realicen varios trabajos de configuración cuando se llaman por primera vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 76.4 ms, sys: 60.5 ms, total: 137 ms\n",
      "Wall time: 76.6 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2661358724"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time df_p.amount.sum().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al archivar datos, es común ordenar y dividir por una columna con identificadores únicos, para facilitar búsquedas rápidas más adelante. Para estos datos, esa columna es \"id\". Mide cuánto tiempo lleva recuperar las filas correspondientes a `id == 100` del CSV sin procesar, de HDF5 y versiones de parquet, y finalmente de una nueva versión de parquet escrita después de aplicar `set_index('id')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_p.set_index('id').to_parquet(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Archivos remotos</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask puede acceder a varios servicios de almacenamiento de datos orientados a la nube y al clúster, como Amazon S3 o HDFS\n",
    "\n",
    "Ventajas:\n",
    "* almacenamiento seguro y escalable\n",
    "\n",
    "Desventajas:\n",
    "* la velocidad de la red se convierte en un cuello de botella"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La forma de configurar marcos de datos (y otras colecciones) sigue siendo muy similar a antes. Tenga en cuenta que los datos aquí están disponibles de forma anónima, pero en general se puede pasar un parámetro adicional `storage_options =` con más detalles sobre cómo interactuar con el almacenamiento remoto.\n",
    "\n",
    "```python\n",
    "taxi = dd.read_csv('s3://nyc-tlc/trip data/yellow_tripdata_2015-*.csv',\n",
    "                   storage_options={'anon': True})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advertencia**: las operaciones a través de Internet pueden tardar mucho en ejecutarse. Estas operaciones funcionan muy bien en una configuración en clúster en la nube, por ejemplo, máquinas de Amazon EC2 que leen desde S3 o máquinas de cómputo de Google que leen desde GCS."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
